{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "826a8964-4435-4c98-96e5-fb77e2a851c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sc\n",
    "from scipy import signal as sig\n",
    "import wfdb\n",
    "from wfdb import processing as wfdbp\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e070379b-c0c3-4c05-9eba-1dbd9c71d26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ECG Denoising\n",
    "fs = 360\n",
    "\n",
    "def pli_filtering(signal, fs, Q = 20, pl_freq = 60): #PLI filtering (60 Hz), Quality factor: 20\n",
    "    wc = pl_freq / (fs / 2)\n",
    "    b, a = sig.iirnotch(wc, Q)\n",
    "    return sig.filtfilt(b, a, signal)\n",
    "\n",
    "def bw_filtering(signal, fs, N = 2, bw_freq = 0.5): #Baseline Wander filtering (0.5 Hz), Butterworth order: 2\n",
    "    wc = bw_freq / (fs / 2)\n",
    "    b, a = sig.butter(N, wc, 'high')\n",
    "    return sig.filtfilt(b, a, signal)\n",
    "    \n",
    "def lp_filtering(signal, fs, N = 2, fc = 150): #LP filtering (150 Hz), Butterworth order: 2\n",
    "    wc = fc / (fs / 2)\n",
    "    b, a = sig.butter(N, wc, 'low')\n",
    "    return sig.filtfilt(b, a, signal)\n",
    "\n",
    "\n",
    "def ecg_denoising(signal, fs):\n",
    "    signal1 = lp_filtering(signal, fs)\n",
    "    signal2 = bw_filtering(signal1, fs)\n",
    "    signal3 = pli_filtering(signal2, fs)\n",
    "    return signal3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3f4b2154-c9c0-4839-951f-b544efdb24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ECG Segmentation\n",
    "\n",
    "def get_sig_ann_fromId(rec_id):\n",
    "    \n",
    "    path = 'mit-bih-arrhythmia-database-1.0.0'\n",
    "    record = wfdb.rdrecord(path + '/' + rec_id)\n",
    "    ann = wfdb.rdann(path + '/' + rec_id, 'atr')\n",
    "\n",
    "    # All annotation sample indices:\n",
    "    all_ann_samples = np.asarray(ann.sample)\n",
    "    all_ann_symbols = np.asarray(ann.symbol)\n",
    "\n",
    "    BEAT_SYMBOLS = {\n",
    "        # Normal / bundle branch blocks:\n",
    "        'N','L','R','e','j',\n",
    "        # Supraventricular:\n",
    "        'A','a','J','S',\n",
    "        # Ventricular:\n",
    "        'V','E',\n",
    "        # Fusion:\n",
    "        'F',\n",
    "        # Other:\n",
    "        '/','Q', 'f'\n",
    "    }\n",
    "\n",
    "    is_beat = np.isin(all_ann_symbols, list(BEAT_SYMBOLS))\n",
    "    beat_indices = all_ann_samples[is_beat]    \n",
    "    beat_symbols = all_ann_symbols[is_beat]  \n",
    "    signal = record.p_signal[:,0] #Single lead\n",
    "    return signal, ann\n",
    "\n",
    "\n",
    "def simplify_types(annotations): #I will simplify to Normal, Supraventricular, Ventricular and Fusion beats, classifying will be performed with arrythmic (Supra, Ventri and Fusion) / non-arryhmic (Normal)\n",
    "\n",
    "    ann_samples = np.asarray(annotations.sample)\n",
    "    ann_symbols = np.asarray(annotations.symbol)\n",
    "    \n",
    "    for i in range(len(ann_samples)): #Could optimize this for sure\n",
    "        if ann_symbols[i] in ['N', 'L', 'R', 'e', 'j']: #Normal\n",
    "            ann_symbols[i] = 'N'\n",
    "        elif ann_symbols[i] in ['A', 'a', 'J', 'S']: #Supraventricular\n",
    "            ann_symbols[i] = 'S'\n",
    "        elif ann_symbols[i] in['V', 'E']: #Ventricular\n",
    "            ann_symbols[i] = 'V'\n",
    "        elif ann_symbols[i] in ['F']: #Fusion\n",
    "            ann_symbols[i] = 'F'\n",
    "        elif ann_symbols[i] in ['/', 'Q', 'f']:\n",
    "            ann_symbols[i] = 'Unk'\n",
    "\n",
    "    good_beat = np.isin(ann_symbols, ['N', 'S', 'V', 'F', 'Unk']) \n",
    "    beat_indices = ann_samples[good_beat]    \n",
    "    beat_symbols = ann_symbols[good_beat]  \n",
    "\n",
    "    return beat_indices, beat_symbols\n",
    "\n",
    "def get_segments(record, annotations, fs = 360, n = 5, ins_num = 1000, min_beats = 1):\n",
    "    #n = Number of beats contained within each instance\n",
    "    beat_ranges = [int(-0.2 * fs), int(0.4 * fs)]#beat_ranges: For now fixed (-0.2s from first beat to +0.4s from last beat)\n",
    "    \n",
    "    beat_indices, beat_symbols = simplify_types(annotations)\n",
    "    segments = [] #Beat signal associated with each instance, won´t be stored in attribute array, but will have same index as ID\n",
    "    beat_types = [] #Same as segments, will not a direct attribute, but will be stored with the same ID (Stored in ASCII value)\n",
    "    rel_indices = [] #Relative peak indices for each segment\n",
    "    \n",
    "    max_segments = max(0, len(beat_indices) - (n - 1))\n",
    "    seg_num = min(ins_num, max_segments)\n",
    "    instances = np.full((seg_num, 10), np.nan, dtype=float)\n",
    "    \n",
    "    for i in range(seg_num):\n",
    "        types = [] #Sublist for beat_types within each segment\n",
    "        indices = [] #Sublist for rel_indices within each segment\n",
    "        start = max(beat_indices[i] + beat_ranges[0], 0)\n",
    "        end = min(beat_indices[i + n - 1] + beat_ranges[1], len(record))\n",
    "        segments.append(record[start : end])\n",
    "\n",
    "        isArrythmic = 0.0\n",
    "        arr_beat_counter = 0\n",
    "        for peak in range(i, i + n):\n",
    "            types.append(beat_symbols[peak]) \n",
    "            indices.append(beat_indices[peak] - start)\n",
    "            if beat_symbols[peak] not in ['N', 'Unk']:\n",
    "                arr_beat_counter += 1\n",
    "        if arr_beat_counter >= min_beats:\n",
    "            isArrythmic = 1.0\n",
    "        beat_types.append(types)\n",
    "        rel_indices.append(indices)\n",
    "\n",
    "        instances[i, 0] = i\n",
    "        instances[i, 1] = isArrythmic\n",
    "        \n",
    "    return instances, segments, beat_types, rel_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "83a334c2-c372-48b6-91f1-f1ed2fdbb98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection (Methods)\n",
    "\n",
    "#def compute_mean(segment):\n",
    "#    return np.mean(segment)\n",
    "\n",
    "def compute_rmssd(indices, fs): #Computed through indices, not Pan-Tomkins\n",
    "    return np.sqrt(np.mean(np.diff(indices) ** 2)) / fs \n",
    "\n",
    "def compute_std_rr(indices, fs): #Computes std between beat R-R intervals\n",
    "    return np.std(np.diff(indices) / fs)\n",
    "\n",
    "def compute_rms(segment):\n",
    "    return np.sqrt(np.mean(segment ** 2))\n",
    "\n",
    "def compute_mean_qrs_length(on, off, fs):\n",
    "    return np.mean(off - on) / fs\n",
    "\n",
    "def compute_relative_qrs_energy(segment, on, off): #Computes the ratio between the QRS segments energy and the total energy \n",
    "    total_energy = np.sum(segment ** 2)\n",
    "    qrs_energy = 0\n",
    "    for i in range(len(on)):\n",
    "        for j in range(on[i], off[i]):\n",
    "            qrs_energy += segment[j] ** 2\n",
    "    return qrs_energy / total_energy\n",
    "\n",
    "def compute_mean_peak_amp(segment, indices):\n",
    "    return np.mean(abs(segment[indices] - np.median(segment)))\n",
    "    \n",
    "def compute_psd(segment, fs): #PSD computed through Welch´s (in Hz)\n",
    "    return sig.welch(segment - np.mean(segment), fs)\n",
    "\n",
    "def compute_relative_power(f, Pxx, bw): #Computes the ratio between the power of the specified band and the whole psd\n",
    "    total_power = np.trapz(Pxx, f)\n",
    "    idx = (f >= bw[0]) & (f <= bw[1])\n",
    "    qrs_power = np.trapz(Pxx[idx], f[idx])\n",
    "    return qrs_power / total_power\n",
    "#QRS Complex: (5 - 15Hz), T Wave: (0.5 - 10 Hz), P Wave: (5 - 30 Hz)\n",
    "    \n",
    "def compute_power_percentile(f, Pxx, bw = [0.5, 40], percentile = 0.95): #Computes within the specified bw in which frequency value the cumulative power reached the specified percentile\n",
    "    idx = (f >= bw[0]) & (f <= bw[1])\n",
    "    f_band = f[idx]\n",
    "    P_band = Pxx[idx]\n",
    "\n",
    "    df = np.diff(f_band)\n",
    "    df = np.r_[df, df[-1]]\n",
    "\n",
    "    cum_power = np.cumsum(P_band * df)\n",
    "    cum_power /= cum_power[-1]\n",
    "\n",
    "    return f_band[np.searchsorted(cum_power, percentile)]\n",
    "#I will try using a .95 percentile for the bw that contains the most relevant ECG freq. components (0.5 - 40 Hz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "c482f44f-854b-4437-8b65-b91e0ddcc32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Selection\n",
    "#Features: 0.ID, 1.Arrythmic? (Contains 1+ Arrythmic beat) [0: True, 1:False], 2.RMSSD, 3.Std_RR, 4.RMS_ECG, \n",
    "#5.Mean QRS Length, 6.QRS Energy ratio, 7.Mean R peak amp, 8.QRS band Power ratio, 9. Frequency at 0.95 power within (0.5 - 40 Hz)\n",
    "\n",
    "def feature_selection(instances, segments, indices, fs = 360):\n",
    "    for i in range(len(instances)):\n",
    "        #Time features\n",
    "        instances[i, 2] = compute_rmssd(indices[i], fs) #RMSSD (Root mean squared successive diffs),\n",
    "        instances[i, 3] = compute_std_rr(indices[i], fs) #3.Std between beats (R-R interval)\n",
    "        instances[i, 4] = compute_rms(segments[i]) #4.Rms of ECG amplitude\n",
    "        on, off, act = qrs_onset_offset(segments[i], indices[i], fs)\n",
    "        instances[i, 5] = compute_mean_qrs_length(on, off, fs) #5.Mean QRS Length (Duration)\n",
    "        instances[i, 6] = compute_relative_qrs_energy(segments[i], on, off) #6.QRS Energy Ratio\n",
    "        instances[i, 7] = compute_mean_peak_amp(segments[i], indices[i]) #7. Mean R peak amp\n",
    "        \n",
    "        #Freq. features\n",
    "        f, Pxx = compute_psd(segments[i], fs)\n",
    "        instances[i, 8] = compute_relative_power(f, Pxx, [5, 15]) #8. QRS band Power Ratio\n",
    "        instances[i, 9] = compute_power_percentile(f, Pxx, [0.5, 40], 0.95) #Frequency at 0.95 power within [0.5 - 40 Hz]      \n",
    "        \n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "669d446e-e26e-4cfb-8edc-ba7eb73efb3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Detect QRS complex onset and offset (for now I will use Pan-Tomkins)\n",
    "\n",
    "def pass_band_filtering(segment, fs = 360, low = 5, high = 15, N = 2): # 5 - 15 Hz (from the paper)\n",
    "    low_c = low / (fs/2)\n",
    "    high_c = high / (fs/2)\n",
    "    b,a = sig.butter(N, [low_c, high_c], 'bandpass')\n",
    "    return sig.filtfilt(b, a, segment)\n",
    "\n",
    "def sav_golay(segment, fs = 360, polyorder = 3, deriv = 1, window = 13): #Savinsky-Golay differentiator\n",
    "    return sig.savgol_filter(segment, window, polyorder, deriv, (1/fs), mode = 'interp')\n",
    "\n",
    "def ma_integration(segment, fs = 360, window = int(0.05 * fs)): #150 ms (from the paper), 50 ms for clearer QRS isolation\n",
    "    b = np.ones(window) / window\n",
    "    return sig.filtfilt(b, 1, segment)\n",
    "\n",
    "#1.Bandpass filtering --> 2.Differentiation --> 3.Squaring --> 4.MA Itegration\n",
    "def pan_tomkins(segment, fs = 360):\n",
    "    segment_f = pass_band_filtering(segment, fs)\n",
    "    segment_d = sav_golay(segment_f, fs)\n",
    "    segment_s = segment_d ** 2\n",
    "    segment_i = ma_integration(segment_s, fs)\n",
    "    return segment_i\n",
    "\n",
    "#Compute the onset & offset\n",
    "def qrs_onset_offset(segment, indices, fs, back_ms = 180, fwd_ms = 20, base_ms = (-220, -140), alpha = 0.25, hold_ms = 30):\n",
    "    \n",
    "    #alpha: Threshold (activity peak fraction)\n",
    "    #hold_ms: It must remain below hold_ms to confirm a return to baseline\n",
    "    \n",
    "    act = pan_tomkins(segment, fs)\n",
    "\n",
    "    back = int(back_ms * fs / 1000)\n",
    "    fwd  = int(fwd_ms  * fs / 1000)\n",
    "    hold = max(1, int(hold_ms * fs / 1000))\n",
    "\n",
    "    on  = np.full(len(indices), -1, dtype=int)\n",
    "    off = np.full(len(indices), -1, dtype=int)\n",
    "\n",
    "    for i, r in enumerate(indices):\n",
    "        lo = max(r - back, 0)\n",
    "        hi = min(r + fwd, len(act) - 1)\n",
    "\n",
    "        #base: baseline\n",
    "        b0 = max(r + int(base_ms[0] * fs / 1000), 0)\n",
    "        b1 = min(r + int(base_ms[1] * fs / 1000), len(act))\n",
    "        base = np.median(act[b0:b1]) if b1 > b0 else np.median(act[lo:r])\n",
    "\n",
    "        peak = np.max(act[lo:hi+1])\n",
    "        thr = base + alpha * (peak - base)\n",
    "\n",
    "        # onset: Backwards until below threshold during hold\n",
    "        onset = lo\n",
    "        for k in range(r, lo, -1):\n",
    "            if np.all(act[max(k - hold, 0) : k] < thr):\n",
    "                onset = k\n",
    "                break\n",
    "\n",
    "        # offset: Forwards until below threshold during hold\n",
    "        offset = hi\n",
    "        for k in range(r, hi-hold):\n",
    "            if np.all(act[k : k + hold] < thr):\n",
    "                offset = k\n",
    "                break\n",
    "\n",
    "        on[i] = onset\n",
    "        off[i] = offset\n",
    "\n",
    "    return on, off, act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "965345c9-b3a3-4043-8e6a-cbef8dc80a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save features in CSV\n",
    "LABEL_COLUMN = \"Arrhythmic\"\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    \"RMSSD\",\n",
    "    \"Std_RR\",\n",
    "    \"RMS_ECG\",\n",
    "    \"Mean_QRS_Length\",\n",
    "    \"QRS_Energy_Ratio\",\n",
    "    \"Mean_R_Peak_Amp\",\n",
    "    \"QRS_Band_Power_Ratio\",\n",
    "    \"Freq_95pct_Power\",\n",
    "]\n",
    "\n",
    "def save_features_sklearn(instances, filename, rec_id):\n",
    "    instances = np.asarray(instances)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"RecordID\": rec_id,  # pandas lo replicará a todas las filas\n",
    "        LABEL_COLUMN: instances[:, 1].astype(int),\n",
    "        \"RMSSD\": instances[:, 2],\n",
    "        \"Std_RR\": instances[:, 3],\n",
    "        \"RMS_ECG\": instances[:, 4],\n",
    "        \"Mean_QRS_Length\": instances[:, 5],\n",
    "        \"QRS_Energy_Ratio\": instances[:, 6],\n",
    "        \"Mean_R_Peak_Amp\": instances[:, 7],\n",
    "        \"QRS_Band_Power_Ratio\": instances[:, 8],\n",
    "        \"Freq_95pct_Power\": instances[:, 9],\n",
    "    })\n",
    "\n",
    "    df_sklearn = df[[\"RecordID\", LABEL_COLUMN] + FEATURE_COLUMNS]\n",
    "    df_sklearn.to_csv(filename, index=False)\n",
    "    return df_sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "20d6cd1f-bcae-4ba9-b5f5-f83d662d3ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['100', '101', '103', '105', '106', '108', '109', '111', '112', '113', '114', '115', '116', '117', '118', '119', '121', '122', '123', '124', '200', '201', '202', '203', '205', '207', '208', '209', '210', '212', '213', '214', '215', '219', '220', '221', '222', '223', '228', '230', '231', '232', '233', '234']\n"
     ]
    }
   ],
   "source": [
    "rec_id = []\n",
    "\n",
    "for i in range(25):\n",
    "    if (i == 10) | (i == 20) | (i == 2) | (i == 4) | (i == 7):\n",
    "        continue\n",
    "    rec_id.append(str(100 + i))\n",
    "    \n",
    "for i in range(35):\n",
    "    if(i == 4) | (i == 6) | (i == 11) | (i == 16) | (i == 18) | (i >= 24 | i <= 27) | (i == 29) | (i == 17):\n",
    "        continue\n",
    "    rec_id.append(str(200 + i))\n",
    "\n",
    "                             \n",
    "print(rec_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c3733dc5-b34f-48e5-8b9c-17408c2c8abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 360\n",
    "\n",
    "for n in [3, 5, 7]:\n",
    "    all_rows = []\n",
    "    for i in range(len(rec_id)):\n",
    "        signal, ann = get_sig_ann_fromId(rec_id[i])\n",
    "        denoised_signal = ecg_denoising(signal, fs)\n",
    "        instances, segments, beat_types, indices = get_segments(denoised_signal, ann, n = n, min_beats = 1)\n",
    "        instances = feature_selection(instances, segments, indices, fs)\n",
    "        df = save_features_sklearn(instances, 'Data_final/' + str(n) + '_n_' + rec_id[i] + '.csv', rec_id[i])\n",
    "        all_rows.append(df)\n",
    "\n",
    "    final_df = pd.concat(all_rows, ignore_index = True)\n",
    "    final_df.to_csv('Data_final/' + str(n) + '_n_all_records.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa3c797-7d7d-407b-9ab7-5157dac289fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
